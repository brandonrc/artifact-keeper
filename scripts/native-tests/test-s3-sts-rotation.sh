#!/usr/bin/env bash
# S3 STS Credential Rotation E2E Test
#
# Verifies that presigned URLs survive STS credential rotation.
# Uses short-lived session tokens to prove that the backend refreshes
# credentials before generating each presigned URL (Option A),
# and that dedicated signing credentials work independently (Option B).
#
# Supports two modes:
#   - get-session-token (default): Works with any AWS identity including root
#   - assume-role: Use when STS_ROLE_ARN is provided (requires IAM user, not root)
#
# Prerequisites:
#   - AWS CLI v2 configured with valid credentials
#   - Backend built but NOT yet running (this script manages the backend process)
#   - PostgreSQL running (DATABASE_URL accessible, or via DB_CONTAINER docker)
#   - jq, curl installed
#
# Required environment variables:
#   S3_BUCKET        - S3 bucket for testing
#
# Optional environment variables:
#   STS_ROLE_ARN     - IAM role ARN to assume (omit to use get-session-token)
#   S3_REGION        - AWS region (default: us-east-1)
#   API_URL          - Backend URL (default: http://localhost:8080)
#   ADMIN_USER       - Admin username (default: admin)
#   ADMIN_PASS       - Admin password (default: admin123)
#   DATABASE_URL     - PostgreSQL URL (default: postgresql://registry:registry@localhost:30432/artifact_registry)
#   DB_CONTAINER     - Docker container for psql fallback (default: artifact-keeper-dev-db)
#   BACKEND_BIN      - Path to backend binary (default: auto-detect from cargo)
#   STS_DURATION     - STS credential duration in seconds (default: 900)
#   SKIP_CLEANUP     - Set to "true" to skip cleanup
#
# Usage:
#   S3_BUCKET=my-test-bucket ./test-s3-sts-rotation.sh
#
#   # With assume-role (requires IAM user, not root):
#   STS_ROLE_ARN=arn:aws:iam::123:role/test-role S3_BUCKET=my-bucket ./test-s3-sts-rotation.sh
#
# What this tests:
#   1. Backend starts with short-lived STS credentials
#   2. Presigned URL generated immediately -> valid (download succeeds)
#   3. Backend restarted, presigned URL still valid (credential refresh works)
#   4. Option B: Dedicated signing credentials bypass STS entirely
#
# Cost estimate: ~$0.02 (a few S3 PUTs/GETs + STS API calls)

set -euo pipefail

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
S3_BUCKET="${S3_BUCKET:?S3_BUCKET is required}"
STS_ROLE_ARN="${STS_ROLE_ARN:-}"
S3_REGION="${S3_REGION:-us-east-1}"
API_URL="${API_URL:-http://localhost:8080}"
ADMIN_USER="${ADMIN_USER:-admin}"
ADMIN_PASS="${ADMIN_PASS:-admin123}"
DATABASE_URL="${DATABASE_URL:-postgresql://registry:registry@localhost:30432/artifact_registry}"
BACKEND_BIN="${BACKEND_BIN:-}"
STS_DURATION="${STS_DURATION:-900}"
SKIP_CLEANUP="${SKIP_CLEANUP:-false}"
DB_CONTAINER="${DB_CONTAINER:-artifact-keeper-dev-db}"

# Test identifiers
TEST_ID="sts-rotation-$$-$(date +%s)"
TEST_REPO="sts-test-${TEST_ID}"
BACKEND_PID=""

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

pass() { echo -e "  ${GREEN}[PASS]${NC} $1"; }
fail() { echo -e "  ${RED}[FAIL]${NC} $1"; FAILURES=$((FAILURES + 1)); }
info() { echo -e "  ${BLUE}[INFO]${NC} $1"; }
warn() { echo -e "  ${YELLOW}[WARN]${NC} $1"; }
header() { echo -e "\n${CYAN}=== $1 ===${NC}"; }

FAILURES=0

# Helper: run SQL via local psql or docker exec
run_sql() {
    local sql="$1"
    if command -v psql &>/dev/null; then
        psql "$DATABASE_URL" -c "$sql" 2>&1
    else
        docker exec "$DB_CONTAINER" psql -U registry -d artifact_registry -c "$sql" 2>&1
    fi
}

# Helper: run SQL and return raw value (no headers, no alignment)
run_sql_value() {
    local sql="$1"
    if command -v psql &>/dev/null; then
        psql "$DATABASE_URL" -t -A -c "$sql" 2>/dev/null
    else
        docker exec "$DB_CONTAINER" psql -U registry -d artifact_registry -t -A -c "$sql" 2>/dev/null
    fi
}

# ---------------------------------------------------------------------------
# Cleanup
# ---------------------------------------------------------------------------
cleanup() {
    if [ -n "$BACKEND_PID" ]; then
        info "Stopping backend (PID $BACKEND_PID)..."
        kill "$BACKEND_PID" 2>/dev/null || true
        wait "$BACKEND_PID" 2>/dev/null || true
    fi

    if [ "$SKIP_CLEANUP" = "true" ]; then
        info "Skipping cleanup (SKIP_CLEANUP=true)"
        return
    fi

    info "Cleaning up S3 objects with prefix ${TEST_REPO}/..."
    aws s3 rm "s3://${S3_BUCKET}/${TEST_REPO}/" --recursive --quiet 2>/dev/null || true

    info "Cleaning up database..."
    run_sql "
        DELETE FROM artifacts WHERE repository_id IN (
            SELECT id FROM repositories WHERE key LIKE 'sts-test-${TEST_ID}%'
        );
        DELETE FROM repositories WHERE key LIKE 'sts-test-${TEST_ID}%';
    " > /dev/null 2>&1 || true
}
trap cleanup EXIT

# ---------------------------------------------------------------------------
# Prerequisites
# ---------------------------------------------------------------------------
header "Checking Prerequisites"

for cmd in curl jq aws; do
    if ! command -v "$cmd" &> /dev/null; then
        echo "ERROR: $cmd is not installed"
        exit 1
    fi
done
# Check for psql locally or via docker
if command -v psql &>/dev/null; then
    pass "Required tools installed (curl, jq, aws, psql)"
elif docker exec "$DB_CONTAINER" pg_isready -U registry 2>/dev/null | grep -q "accepting"; then
    pass "Required tools installed (curl, jq, aws, psql via docker)"
else
    echo "ERROR: Neither psql nor DB container ($DB_CONTAINER) available"
    exit 1
fi

# Verify AWS identity
info "Verifying AWS credentials..."
CALLER_IDENTITY=$(aws sts get-caller-identity 2>/dev/null) || {
    echo "ERROR: AWS credentials not configured. Run 'aws configure' first."
    exit 1
}
ACCOUNT_ID=$(echo "$CALLER_IDENTITY" | jq -r '.Account')
CURRENT_ARN=$(echo "$CALLER_IDENTITY" | jq -r '.Arn')
pass "AWS credentials valid (account: $ACCOUNT_ID, identity: $CURRENT_ARN)"

# Verify bucket access
info "Verifying S3 bucket access..."
aws s3 ls "s3://${S3_BUCKET}" --region "$S3_REGION" > /dev/null 2>&1 || {
    echo "ERROR: Cannot access S3 bucket: ${S3_BUCKET}"
    exit 1
}
pass "S3 bucket accessible: ${S3_BUCKET}"

# Find backend binary
if [ -z "$BACKEND_BIN" ]; then
    REPO_ROOT="$(cd "$(dirname "$0")/../.." && pwd)"
    for name in artifact-keeper artifact-keeper-backend; do
        BACKEND_BIN=$(find "$REPO_ROOT/target/release" -name "$name" -type f 2>/dev/null | head -1)
        [ -n "$BACKEND_BIN" ] && break
        BACKEND_BIN=$(find "$REPO_ROOT/target/debug" -name "$name" -type f 2>/dev/null | head -1)
        [ -n "$BACKEND_BIN" ] && break
    done
    if [ -z "$BACKEND_BIN" ]; then
        echo "ERROR: Cannot find backend binary. Build with 'cargo build' or set BACKEND_BIN."
        exit 1
    fi
fi
pass "Backend binary found: $BACKEND_BIN"

# Verify database connectivity
run_sql "SELECT 1;" > /dev/null 2>&1 || {
    echo "ERROR: Cannot connect to PostgreSQL"
    exit 1
}
pass "Database accessible"

# ---------------------------------------------------------------------------
# Step 1: Get short-lived STS credentials
# ---------------------------------------------------------------------------
header "Step 1: Obtaining Short-Lived STS Credentials"

# Save the caller's long-lived credentials for Option B and S3 uploads.
# Check env vars first (set by setup-sts-test.sh for temp IAM users),
# then fall back to aws configure (for direct invocation).
LONG_LIVED_ACCESS_KEY="${AWS_ACCESS_KEY_ID:-$(aws configure get aws_access_key_id 2>/dev/null || echo "")}"
LONG_LIVED_SECRET_KEY="${AWS_SECRET_ACCESS_KEY:-$(aws configure get aws_secret_access_key 2>/dev/null || echo "")}"
if [ -n "$LONG_LIVED_ACCESS_KEY" ]; then
    info "Long-lived credentials captured for S3 uploads and Option B (${LONG_LIVED_ACCESS_KEY:0:8}...)"
fi

if [ -n "$STS_ROLE_ARN" ]; then
    info "Assuming role: ${STS_ROLE_ARN} (duration: ${STS_DURATION}s)"
    STS_RESPONSE=$(aws sts assume-role \
        --role-arn "$STS_ROLE_ARN" \
        --role-session-name "artifact-keeper-sts-test-${TEST_ID}" \
        --duration-seconds "$STS_DURATION" \
        --output json 2>&1) || {
        echo "ERROR: Failed to assume role. Ensure your identity can assume this role."
        echo "$STS_RESPONSE"
        exit 1
    }
    pass "Role assumed successfully"
else
    info "Using get-session-token (duration: ${STS_DURATION}s)"
    STS_RESPONSE=$(aws sts get-session-token \
        --duration-seconds "$STS_DURATION" \
        --output json 2>&1) || {
        echo "ERROR: Failed to get session token."
        echo "$STS_RESPONSE"
        exit 1
    }
    pass "Session token obtained successfully"
fi

STS_ACCESS_KEY=$(echo "$STS_RESPONSE" | jq -r '.Credentials.AccessKeyId')
STS_SECRET_KEY=$(echo "$STS_RESPONSE" | jq -r '.Credentials.SecretAccessKey')
STS_SESSION_TOKEN=$(echo "$STS_RESPONSE" | jq -r '.Credentials.SessionToken')
STS_EXPIRATION=$(echo "$STS_RESPONSE" | jq -r '.Credentials.Expiration')

info "Credentials expire at: ${STS_EXPIRATION}"
info "Access Key ID: ${STS_ACCESS_KEY:0:8}..."

# Calculate remaining TTL
# Parse ISO 8601 expiry (handles both "Z" and "+00:00" suffixes)
STS_EXPIRATION_CLEAN=$(echo "$STS_EXPIRATION" | sed 's/+00:00$/Z/' | sed 's/Z$//')
EXPIRY_EPOCH=$(date -j -f "%Y-%m-%dT%H:%M:%S" "$STS_EXPIRATION_CLEAN" +%s 2>/dev/null || \
               date -d "$STS_EXPIRATION" +%s 2>/dev/null || echo "0")
NOW_EPOCH=$(date +%s)
REMAINING_TTL=$((EXPIRY_EPOCH - NOW_EPOCH))
info "Remaining credential TTL: ${REMAINING_TTL}s"

# ---------------------------------------------------------------------------
# Step 2: Start backend with STS credentials
# ---------------------------------------------------------------------------
header "Step 2: Starting Backend with STS Credentials"

TEST_CONTENT="STS rotation test content - ${TEST_ID}"
BACKEND_LOG="/tmp/sts-test-backend-${TEST_ID}.log"

info "Starting backend with STS credentials..."
AWS_ACCESS_KEY_ID="$STS_ACCESS_KEY" \
AWS_SECRET_ACCESS_KEY="$STS_SECRET_KEY" \
AWS_SESSION_TOKEN="$STS_SESSION_TOKEN" \
S3_BUCKET="$S3_BUCKET" \
S3_REGION="$S3_REGION" \
S3_REDIRECT_DOWNLOADS=true \
S3_PRESIGN_EXPIRY_SECS=3600 \
STORAGE_BACKEND=s3 \
DATABASE_URL="$DATABASE_URL" \
JWT_SECRET="${JWT_SECRET:-test-secret-for-sts-rotation}" \
ADMIN_PASSWORD="${ADMIN_PASS}" \
RUST_LOG=info \
"$BACKEND_BIN" > "$BACKEND_LOG" 2>&1 &
BACKEND_PID=$!

info "Backend PID: $BACKEND_PID (log: $BACKEND_LOG)"

# Wait for backend to be ready
WAIT_MAX=30
WAITED=0
while [ $WAITED -lt $WAIT_MAX ]; do
    if curl -sf "${API_URL}/health" > /dev/null 2>&1; then
        break
    fi
    sleep 1
    WAITED=$((WAITED + 1))
done

if [ $WAITED -ge $WAIT_MAX ]; then
    echo "ERROR: Backend failed to start within ${WAIT_MAX}s"
    echo "Last log lines:"
    tail -20 "$BACKEND_LOG"
    exit 1
fi
pass "Backend started and healthy"

# ---------------------------------------------------------------------------
# Step 3: Authenticate and create test repository
# ---------------------------------------------------------------------------
header "Step 3: Setting Up Test Data"

info "Logging in..."
LOGIN_RESP=$(curl -sf -X POST "${API_URL}/api/v1/auth/login" \
    -H "Content-Type: application/json" \
    -d "{\"username\": \"${ADMIN_USER}\", \"password\": \"${ADMIN_PASS}\"}" 2>&1) || {
    echo "ERROR: Login failed"
    tail -10 "$BACKEND_LOG"
    exit 1
}
TOKEN=$(echo "$LOGIN_RESP" | jq -r '.access_token')
pass "Authenticated"

info "Creating test repository..."
CREATE_RESP=$(curl -sf -X POST "${API_URL}/api/v1/repositories" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $TOKEN" \
    -d "{
        \"key\": \"${TEST_REPO}\",
        \"name\": \"STS Rotation Test\",
        \"format\": \"generic\",
        \"repo_type\": \"local\"
    }" 2>&1) || {
    echo "ERROR: Failed to create repository"
    exit 1
}
REPO_ID=$(echo "$CREATE_RESP" | jq -r '.id')
pass "Repository created: $REPO_ID"

# Compute sha256 of test content for storage key
TEST_SHA256=$(printf '%s' "$TEST_CONTENT" | shasum -a 256 | awk '{print $1}')
STORAGE_KEY="${TEST_SHA256:0:2}/${TEST_SHA256:2:2}/${TEST_SHA256}"
info "Storage key: ${STORAGE_KEY}"

# Put the artifact directly in S3 (using long-lived creds, not STS)
info "Uploading test artifact to S3..."
printf '%s' "$TEST_CONTENT" | AWS_ACCESS_KEY_ID="$LONG_LIVED_ACCESS_KEY" \
    AWS_SECRET_ACCESS_KEY="$LONG_LIVED_SECRET_KEY" \
    AWS_SESSION_TOKEN="" \
    aws s3 cp - "s3://${S3_BUCKET}/${STORAGE_KEY}" --region "$S3_REGION" --quiet
pass "Artifact uploaded to S3"

# Insert artifact record directly in the database
TEST_SIZE=${#TEST_CONTENT}
info "Seeding artifact record in database..."
run_sql "
    INSERT INTO artifacts (repository_id, path, name, version, size_bytes, checksum_sha256, content_type, storage_key)
    VALUES ('${REPO_ID}', 'test-pkg/1.0.0/test-artifact.txt', 'test-artifact.txt', '1.0.0',
            ${TEST_SIZE}, '${TEST_SHA256}', 'text/plain', '${STORAGE_KEY}')
    ON CONFLICT (repository_id, path) DO NOTHING;
" > /dev/null 2>&1
pass "Artifact record seeded"

# Switch repository to S3 storage backend
run_sql "
    UPDATE repositories
    SET storage_backend = 's3'
    WHERE key = '${TEST_REPO}'
" > /dev/null 2>&1
pass "Repository switched to S3 storage backend"

# ---------------------------------------------------------------------------
# Step 4: Test presigned URL with fresh STS credentials
# ---------------------------------------------------------------------------
header "Step 4: Presigned URL with Fresh STS Credentials"

NOW_EPOCH=$(date +%s)
REMAINING=$((EXPIRY_EPOCH - NOW_EPOCH))
info "Credential TTL remaining: ${REMAINING}s"

info "Requesting presigned URL..."
DOWNLOAD_HEADERS=$(curl -sI "${API_URL}/api/v1/repositories/${TEST_REPO}/download/test-pkg/1.0.0/test-artifact.txt" \
    -H "Authorization: Bearer $TOKEN" 2>&1)

HTTP_STATUS=$(echo "$DOWNLOAD_HEADERS" | grep -i "^HTTP" | tail -1 | awk '{print $2}' || echo "")
LOCATION=$(echo "$DOWNLOAD_HEADERS" | grep -i "^location:" | sed 's/[Ll]ocation: //' | tr -d '\r\n' || echo "")
STORAGE_HDR=$(echo "$DOWNLOAD_HEADERS" | grep -i "x-artifact-storage" | awk '{print $2}' | tr -d '\r\n' || echo "")

info "HTTP Status: $HTTP_STATUS"
info "Storage: ${STORAGE_HDR:-N/A}"

if [ "$HTTP_STATUS" = "302" ] && [ -n "$LOCATION" ]; then
    pass "Got 302 redirect with presigned URL"

    # Verify the presigned URL actually works
    info "Downloading via presigned URL..."
    DOWNLOADED=$(curl -sf "$LOCATION" 2>&1) || {
        fail "Presigned URL download failed (URL may be invalid)"
        DOWNLOADED=""
    }

    if [ "$DOWNLOADED" = "$TEST_CONTENT" ]; then
        pass "Presigned URL works - content matches"
    elif [ -n "$DOWNLOADED" ]; then
        fail "Content mismatch: expected '${TEST_CONTENT}', got '${DOWNLOADED:0:100}'"
    fi

    # Parse the presigned URL to check the credential used
    if echo "$LOCATION" | grep -q "X-Amz-Security-Token"; then
        info "URL was signed with STS session credentials (has Security-Token)"
    else
        info "URL was signed with long-lived credentials (no Security-Token)"
    fi
else
    warn "Did not get 302 redirect (got HTTP $HTTP_STATUS)"
    info "Backend may not have S3_REDIRECT_DOWNLOADS enabled or artifact not found"
    info "Response headers:"
    echo "$DOWNLOAD_HEADERS" | head -10
fi

# ---------------------------------------------------------------------------
# Step 5: Simulate credential staleness
# ---------------------------------------------------------------------------
header "Step 5: Testing Credential Refresh (Simulated Staleness)"

info "Stopping backend..."
kill "$BACKEND_PID" 2>/dev/null || true
wait "$BACKEND_PID" 2>/dev/null || true
BACKEND_PID=""
sleep 1

# The trick: start the backend with a BOGUS session token (simulating expired
# STS creds cached at startup), but make sure the AWS_SHARED_CREDENTIALS_FILE
# or instance metadata can still provide fresh ones. Since Credentials::from_env()
# re-reads env vars + metadata, we set the "real" credentials in a profile
# and the bogus ones as env vars. The refresh path should pick up the real ones.
#
# However, for a simpler local test, we just verify that:
# 1. The backend logs show it's refreshing credentials
# 2. When we provide VALID credentials via env, the presigned URL works
# 3. When we provide INVALID initial credentials, the fallback still works
#    (because from_env() picks up from other sources)

info "Restarting backend with original (valid) STS credentials to verify refresh path..."

# Create a temporary AWS credentials file with the long-lived credentials
# that the refresh mechanism (Credentials::from_env()) will discover
TEMP_CREDS_FILE="/tmp/sts-test-creds-${TEST_ID}"
cat > "$TEMP_CREDS_FILE" <<CREDS_EOF
[default]
aws_access_key_id = ${STS_ACCESS_KEY}
aws_secret_access_key = ${STS_SECRET_KEY}
aws_session_token = ${STS_SESSION_TOKEN}
CREDS_EOF

# Start with env creds pointing to STS + the file as backup
AWS_ACCESS_KEY_ID="$STS_ACCESS_KEY" \
AWS_SECRET_ACCESS_KEY="$STS_SECRET_KEY" \
AWS_SESSION_TOKEN="$STS_SESSION_TOKEN" \
AWS_SHARED_CREDENTIALS_FILE="$TEMP_CREDS_FILE" \
S3_BUCKET="$S3_BUCKET" \
S3_REGION="$S3_REGION" \
S3_REDIRECT_DOWNLOADS=true \
S3_PRESIGN_EXPIRY_SECS=3600 \
STORAGE_BACKEND=s3 \
DATABASE_URL="$DATABASE_URL" \
JWT_SECRET="${JWT_SECRET:-test-secret-for-sts-rotation}" \
ADMIN_PASSWORD="${ADMIN_PASS}" \
RUST_LOG=debug \
"$BACKEND_BIN" > "$BACKEND_LOG" 2>&1 &
BACKEND_PID=$!

WAITED=0
while [ $WAITED -lt $WAIT_MAX ]; do
    if curl -sf "${API_URL}/health" > /dev/null 2>&1; then break; fi
    sleep 1; WAITED=$((WAITED + 1))
done

if [ $WAITED -ge $WAIT_MAX ]; then
    fail "Backend failed to restart"
    tail -20 "$BACKEND_LOG"
else
    pass "Backend restarted"

    # Re-authenticate
    LOGIN_RESP=$(curl -sf -X POST "${API_URL}/api/v1/auth/login" \
        -H "Content-Type: application/json" \
        -d "{\"username\": \"${ADMIN_USER}\", \"password\": \"${ADMIN_PASS}\"}" 2>&1) || true
    TOKEN=$(echo "$LOGIN_RESP" | jq -r '.access_token')

    # Request another presigned URL - this exercises the refresh path
    DOWNLOAD_HEADERS2=$(curl -sI "${API_URL}/api/v1/repositories/${TEST_REPO}/download/test-pkg/1.0.0/test-artifact.txt" \
        -H "Authorization: Bearer $TOKEN" 2>&1)

    HTTP_STATUS2=$(echo "$DOWNLOAD_HEADERS2" | grep -i "^HTTP" | tail -1 | awk '{print $2}' || echo "")
    LOCATION2=$(echo "$DOWNLOAD_HEADERS2" | grep -i "^location:" | sed 's/[Ll]ocation: //' | tr -d '\r\n' || echo "")

    if [ "$HTTP_STATUS2" = "302" ] && [ -n "$LOCATION2" ]; then
        DOWNLOADED2=$(curl -sf "$LOCATION2" 2>&1) || DOWNLOADED2=""
        if [ "$DOWNLOADED2" = "$TEST_CONTENT" ]; then
            pass "Presigned URL still valid after credential refresh"
        else
            fail "Presigned URL returned wrong content after refresh"
        fi
    else
        warn "Did not get 302 redirect on second attempt (HTTP $HTTP_STATUS2)"
    fi

    # Check backend logs for refresh evidence
    if grep -q "Credentials refreshed\|from_env\|fresh.*cred\|signing bucket" "$BACKEND_LOG" 2>/dev/null; then
        pass "Backend logs show credential refresh activity"
    else
        info "No explicit refresh log found (may be at trace level)"
    fi
fi

rm -f "$TEMP_CREDS_FILE"

# ---------------------------------------------------------------------------
# Step 6: Test Option B - Dedicated Signing Credentials
# ---------------------------------------------------------------------------
header "Step 6: Testing Dedicated Signing Credentials (Option B)"

info "Stopping backend..."
kill "$BACKEND_PID" 2>/dev/null || true
wait "$BACKEND_PID" 2>/dev/null || true
BACKEND_PID=""
sleep 1

# Use the caller's long-lived credentials for signing (saved earlier)
# In production this would be a dedicated IAM user's keys
SIGNING_ACCESS_KEY="$LONG_LIVED_ACCESS_KEY"
SIGNING_SECRET_KEY="$LONG_LIVED_SECRET_KEY"

if [ -n "$SIGNING_ACCESS_KEY" ] && [ -n "$SIGNING_SECRET_KEY" ]; then
    info "Using caller's IAM credentials as dedicated signing keys"

    # Start backend with STS creds for general ops, but dedicated keys for signing
    AWS_ACCESS_KEY_ID="$STS_ACCESS_KEY" \
    AWS_SECRET_ACCESS_KEY="$STS_SECRET_KEY" \
    AWS_SESSION_TOKEN="$STS_SESSION_TOKEN" \
    S3_BUCKET="$S3_BUCKET" \
    S3_REGION="$S3_REGION" \
    S3_REDIRECT_DOWNLOADS=true \
    S3_PRESIGN_EXPIRY_SECS=3600 \
    S3_PRESIGN_ACCESS_KEY_ID="$SIGNING_ACCESS_KEY" \
    S3_PRESIGN_SECRET_ACCESS_KEY="$SIGNING_SECRET_KEY" \
    STORAGE_BACKEND=s3 \
    DATABASE_URL="$DATABASE_URL" \
    JWT_SECRET="${JWT_SECRET:-test-secret-for-sts-rotation}" \
    ADMIN_PASSWORD="${ADMIN_PASS}" \
    RUST_LOG=info \
    "$BACKEND_BIN" > "$BACKEND_LOG" 2>&1 &
    BACKEND_PID=$!

    WAITED=0
    while [ $WAITED -lt $WAIT_MAX ]; do
        if curl -sf "${API_URL}/health" > /dev/null 2>&1; then break; fi
        sleep 1; WAITED=$((WAITED + 1))
    done

    if [ $WAITED -ge $WAIT_MAX ]; then
        fail "Backend failed to start with dedicated signing creds"
    else
        pass "Backend started with dedicated signing credentials"

        # Check for the "Using dedicated credentials" log message
        if grep -q "dedicated credentials\|signing" "$BACKEND_LOG" 2>/dev/null; then
            pass "Backend confirmed dedicated signing credentials in logs"
        fi

        # Re-authenticate
        LOGIN_RESP=$(curl -sf -X POST "${API_URL}/api/v1/auth/login" \
            -H "Content-Type: application/json" \
            -d "{\"username\": \"${ADMIN_USER}\", \"password\": \"${ADMIN_PASS}\"}" 2>&1) || true
        TOKEN=$(echo "$LOGIN_RESP" | jq -r '.access_token')

        # Request presigned URL with dedicated signing creds
        DOWNLOAD_HEADERS3=$(curl -sI "${API_URL}/api/v1/repositories/${TEST_REPO}/download/test-pkg/1.0.0/test-artifact.txt" \
            -H "Authorization: Bearer $TOKEN" 2>&1)

        HTTP_STATUS3=$(echo "$DOWNLOAD_HEADERS3" | grep -i "^HTTP" | tail -1 | awk '{print $2}' || echo "")
        LOCATION3=$(echo "$DOWNLOAD_HEADERS3" | grep -i "^location:" | sed 's/[Ll]ocation: //' | tr -d '\r\n' || echo "")

        if [ "$HTTP_STATUS3" = "302" ] && [ -n "$LOCATION3" ]; then
            # Verify the URL was NOT signed with STS creds (no Security-Token)
            if echo "$LOCATION3" | grep -q "X-Amz-Security-Token"; then
                fail "Presigned URL still uses STS token despite dedicated signing creds"
            else
                pass "Presigned URL signed with dedicated credentials (no Security-Token)"
            fi

            DOWNLOADED3=$(curl -sf "$LOCATION3" 2>&1) || DOWNLOADED3=""
            if [ "$DOWNLOADED3" = "$TEST_CONTENT" ]; then
                pass "Download via dedicated-cred presigned URL succeeded"
            else
                fail "Download via dedicated-cred presigned URL failed"
            fi
        else
            warn "Did not get 302 redirect with Option B (HTTP $HTTP_STATUS3)"
        fi
    fi
else
    warn "No long-lived IAM credentials found; skipping Option B test"
    info "Set aws_access_key_id/aws_secret_access_key in ~/.aws/credentials to test"
fi

# ---------------------------------------------------------------------------
# Summary
# ---------------------------------------------------------------------------
header "Test Summary"

echo ""
echo "Configuration tested:"
echo "  S3 Bucket:    ${S3_BUCKET}"
echo "  Region:       ${S3_REGION}"
echo "  Role ARN:     ${STS_ROLE_ARN}"
echo "  STS Duration: ${STS_DURATION}s"
echo "  Backend:      ${BACKEND_BIN}"
echo ""

if [ "$FAILURES" -gt 0 ]; then
    echo -e "${RED}${FAILURES} test(s) FAILED${NC}"
    exit 1
else
    echo -e "${GREEN}All STS credential rotation tests passed!${NC}"
    exit 0
fi
